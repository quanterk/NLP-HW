{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text=pd.read_csv('movie_classiffier') \n",
    "text.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "text['train']=text['train'].astype(\"str\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京 意淫 了 脑残 地步 看 恶心 想 吐'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from  tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate  , BatchNormalization,Dropout\n",
    "from  tensorflow.keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D,LSTM\n",
    "\n",
    "#from  tensorflow.keras.preprocessing import text, sequence\n",
    "from  tensorflow.keras.callbacks import Callback\n",
    "from  tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "（2014）深南法民二初字第280号\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#判断一段文本中是否包含简体中文\n",
    "\n",
    "import re\n",
    "\n",
    "zhmodel = re.compile(u'[\\u4e00-\\u9fa5]')    #检查中文\n",
    "\n",
    "#zhmodel = re.compile(u'[^\\u4e00-\\u9fa5]')   #检查非中文\n",
    "\n",
    "contents = u'（2014）深南法民二初字第280号'\n",
    "\n",
    "match = zhmodel.search(contents)\n",
    "\n",
    "if match:\n",
    "\n",
    "    print(contents)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(u'没有包含中文')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先取5w个试一试 :去掉字母\n",
    "length=200000\n",
    "def read_data():\n",
    "    data = {}\n",
    "    x, y = [], []\n",
    "  \n",
    "    \n",
    "    for i in range(length):\n",
    "        temp=text.loc[i].train.split()\n",
    "        index=[]\n",
    "        for i in range(len(temp)):\n",
    "            if zhmodel.search(temp[i]):\n",
    "                index.append(i)\n",
    "        temp=[temp[i] for i in index]\n",
    "        x.append(temp)\n",
    "        y.append(text.loc[i].label)\n",
    "    x, y = shuffle(x, y)\n",
    "#     dev_idx =int(length* 0.8    )\n",
    "#     test_idx =int( length* 0.9  )\n",
    "\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train =read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= text.train.fillna(\"fillna\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['吴京 意淫 了 脑残 地步 看 恶心 想 吐',\n",
       "       '首映礼 看 太 恐怖 这个 电影 不讲道理 完全 吴京 实现 这个 小 粉红 英雄 梦 装备 轮番 上场 视 物理 逻辑 不顾 不得不 有钱 真 随意 胡闹',\n",
       "       '吴京 炒作 水平 不输 冯小刚 但小刚 至少 不会 主旋律 炒作 吴京 人 看 不 舒服 主旋律 主旋律 煽情 煽情 人 觉得 是 大 做作 谎言 家 729 更新 片子 整体 不如 湄公河 行动 整体 不够 流畅 编剧 有毒 台词 尴尬 刻意 做作 主旋律 煽情 显得 不合时宜 又 多余',\n",
       "       ..., '喜欢 女主角 希腊 雕塑 的 面庞 身体 一部 同志 题材 电影 迷恋 女主角 好像 不 应该 吧',\n",
       "       '冲着 颜值 可以 看 下去', '除了 主人公 不帅 女主挺 漂亮 之外 唯一 感觉 他 男朋友 真让人 恶心'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = text[['label']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=tensorflow.keras.backend.one_hot(y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=tensorflow.keras.backend.reshape(y_train,(-1,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([261496, 5])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'看': 1,\n",
       " '电影': 2,\n",
       " '的': 3,\n",
       " '是': 4,\n",
       " '啊': 5,\n",
       " '一个': 6,\n",
       " '故事': 7,\n",
       " '我': 8,\n",
       " '没有': 9,\n",
       " '喜欢': 10,\n",
       " '太': 11,\n",
       " '剧情': 12,\n",
       " '没': 13,\n",
       " '吧': 14,\n",
       " '不错': 15,\n",
       " '得': 16,\n",
       " '人': 17,\n",
       " '最后': 18,\n",
       " '一部': 19,\n",
       " '片子': 20,\n",
       " '有': 21,\n",
       " '不': 22,\n",
       " '了': 23,\n",
       " '不是': 24,\n",
       " '很': 25,\n",
       " '觉得': 26,\n",
       " '导演': 27,\n",
       " '拍': 28,\n",
       " '好看': 29,\n",
       " '真的': 30,\n",
       " '感觉': 31,\n",
       " '但是': 32,\n",
       " '有点': 33,\n",
       " '想': 34,\n",
       " '这部': 35,\n",
       " '在': 36,\n",
       " '都': 37,\n",
       " '好': 38,\n",
       " '小': 39,\n",
       " '真是': 40,\n",
       " '这种': 41,\n",
       " '片': 42,\n",
       " '不过': 43,\n",
       " '挺': 44,\n",
       " '就': 45,\n",
       " '却': 46,\n",
       " '爱': 47,\n",
       " '也': 48,\n",
       " '演技': 49,\n",
       " '其实': 50,\n",
       " '看到': 51,\n",
       " '知道': 52,\n",
       " '演员': 53,\n",
       " '真': 54,\n",
       " '时候': 55,\n",
       " '才': 56,\n",
       " '完': 57,\n",
       " '生活': 58,\n",
       " '影片': 59,\n",
       " '非常': 60,\n",
       " '你': 61,\n",
       " '结尾': 62,\n",
       " '很多': 63,\n",
       " '经典': 64,\n",
       " '完全': 65,\n",
       " '镜头': 66,\n",
       " '能': 67,\n",
       " '人物': 68,\n",
       " '这': 69,\n",
       " '打': 70,\n",
       " '死': 71,\n",
       " '情节': 72,\n",
       " '看过': 73,\n",
       " '笑': 74,\n",
       " '实在': 75,\n",
       " '角色': 76,\n",
       " '个': 77,\n",
       " '点': 78,\n",
       " '不能': 79,\n",
       " '现在': 80,\n",
       " '逼': 81,\n",
       " '爱情': 82,\n",
       " '可以': 83,\n",
       " '已经': 84,\n",
       " '表演': 85,\n",
       " '中国': 86,\n",
       " '他': 87,\n",
       " '结局': 88,\n",
       " '还': 89,\n",
       " '戏': 90,\n",
       " '就是': 91,\n",
       " '世界': 92,\n",
       " '节奏': 93,\n",
       " '只': 94,\n",
       " '还是': 95,\n",
       " '一直': 96,\n",
       " '出来': 97,\n",
       " '动作': 98,\n",
       " '烂片': 99,\n",
       " '演': 100,\n",
       " '青春': 101,\n",
       " '说': 102,\n",
       " '比较': 103,\n",
       " '应该': 104,\n",
       " '对': 105,\n",
       " '可爱': 106,\n",
       " '老': 107,\n",
       " '多': 108,\n",
       " '画面': 109,\n",
       " '什么': 110,\n",
       " '一点': 111,\n",
       " '让': 112,\n",
       " '两个': 113,\n",
       " '精彩': 114,\n",
       " '一起': 115,\n",
       " '自己': 116,\n",
       " '作品': 117,\n",
       " '剧本': 118,\n",
       " '风格': 119,\n",
       " '被': 120,\n",
       " '音乐': 121,\n",
       " '配乐': 122,\n",
       " '居然': 123,\n",
       " '人生': 124,\n",
       " '当': 125,\n",
       " '可能': 126,\n",
       " '最': 127,\n",
       " '里面': 128,\n",
       " '要': 129,\n",
       " '题材': 130,\n",
       " '除了': 131,\n",
       " '烂': 132,\n",
       " '哭': 133,\n",
       " '喜剧': 134,\n",
       " '感动': 135,\n",
       " '特别': 136,\n",
       " '不会': 137,\n",
       " '真实': 138,\n",
       " '观众': 139,\n",
       " '美国': 140,\n",
       " '像': 141,\n",
       " '给': 142,\n",
       " '不要': 143,\n",
       " '星': 144,\n",
       " '会': 145,\n",
       " '讲': 146,\n",
       " '一种': 147,\n",
       " '可惜': 148,\n",
       " '以为': 149,\n",
       " '这个': 150,\n",
       " '搞笑': 151,\n",
       " '无聊': 152,\n",
       " '男人': 153,\n",
       " '出': 154,\n",
       " '美': 155,\n",
       " '女人': 156,\n",
       " '简直': 157,\n",
       " '时代': 158,\n",
       " '问题': 159,\n",
       " '时间': 160,\n",
       " '孩子': 161,\n",
       " '台词': 162,\n",
       " '日本': 163,\n",
       " '第一部': 164,\n",
       " '那段': 165,\n",
       " '一星': 166,\n",
       " '这么': 167,\n",
       " '之后': 168,\n",
       " '场面': 169,\n",
       " '东西': 170,\n",
       " '简单': 171,\n",
       " '编剧': 172,\n",
       " '细节': 173,\n",
       " '地方': 174,\n",
       " '现实': 175,\n",
       " '那么': 176,\n",
       " '这是': 177,\n",
       " '一次': 178,\n",
       " '主角': 179,\n",
       " '确实': 180,\n",
       " '版': 181,\n",
       " '只能': 182,\n",
       " '一些': 183,\n",
       " '每个': 184,\n",
       " '所有': 185,\n",
       " '三星': 186,\n",
       " '那': 187,\n",
       " '永远': 188,\n",
       " '完美': 189,\n",
       " '叙事': 190,\n",
       " '起来': 191,\n",
       " '特效': 192,\n",
       " '无法': 193,\n",
       " '希望': 194,\n",
       " '把': 195,\n",
       " '部分': 196,\n",
       " '最好': 197,\n",
       " '本片': 198,\n",
       " '一定': 199,\n",
       " '总是': 200,\n",
       " '原来': 201,\n",
       " '和': 202,\n",
       " '竟然': 203,\n",
       " '又': 204,\n",
       " '看着': 205,\n",
       " '几个': 206,\n",
       " '无': 207,\n",
       " '值得': 208,\n",
       " '男': 209,\n",
       " '这样': 210,\n",
       " '香港': 211,\n",
       " '半': 212,\n",
       " '表现': 213,\n",
       " '我们': 214,\n",
       " '女主': 215,\n",
       " '走': 216,\n",
       " '需要': 217,\n",
       " '成': 218,\n",
       " '一下': 219,\n",
       " '不如': 220,\n",
       " '适合': 221,\n",
       " '懂': 222,\n",
       " '系列': 223,\n",
       " '分钟': 224,\n",
       " '情感': 225,\n",
       " '大': 226,\n",
       " '但': 227,\n",
       " '美好': 228,\n",
       " '小时': 229,\n",
       " '不够': 230,\n",
       " '那个': 231,\n",
       " '算': 232,\n",
       " '剪辑': 233,\n",
       " '感情': 234,\n",
       " '年代': 235,\n",
       " '看看': 236,\n",
       " '尤其': 237,\n",
       " '整个': 238,\n",
       " '终于': 239,\n",
       " '英雄': 240,\n",
       " '那种': 241,\n",
       " '算是': 242,\n",
       " '个人': 243,\n",
       " '社会': 244,\n",
       " '去': 245,\n",
       " '女': 246,\n",
       " '好像': 247,\n",
       " '哈哈哈': 248,\n",
       " '尴尬': 249,\n",
       " '发现': 250,\n",
       " '话': 251,\n",
       " '依然': 252,\n",
       " '唯一': 253,\n",
       " '牛': 254,\n",
       " '差': 255,\n",
       " '傻': 256,\n",
       " '场景': 257,\n",
       " '对于': 258,\n",
       " '倒': 259,\n",
       " '动画': 260,\n",
       " '感': 261,\n",
       " '亮点': 262,\n",
       " '这片': 263,\n",
       " '家庭': 264,\n",
       " '男主': 265,\n",
       " '战争': 266,\n",
       " '蛮': 267,\n",
       " '出现': 268,\n",
       " '人性': 269,\n",
       " '没什么': 270,\n",
       " '电影院': 271,\n",
       " '五星': 272,\n",
       " 'ps': 273,\n",
       " '之前': 274,\n",
       " '后面': 275,\n",
       " '来说': 276,\n",
       " '一段': 277,\n",
       " '摄影': 278,\n",
       " '更': 279,\n",
       " '真正': 280,\n",
       " '印象': 281,\n",
       " '类型': 282,\n",
       " '本身': 283,\n",
       " '绝对': 284,\n",
       " '主题': 285,\n",
       " '年轻': 286,\n",
       " '记得': 287,\n",
       " 'nan': 288,\n",
       " '期待': 289,\n",
       " '找': 290,\n",
       " '当年': 291,\n",
       " '深刻': 292,\n",
       " '一场': 293,\n",
       " '女主角': 294,\n",
       " '励志': 295,\n",
       " '她': 296,\n",
       " '令人': 297,\n",
       " '生命': 298,\n",
       " '事': 299,\n",
       " '感人': 300,\n",
       " '逻辑': 301,\n",
       " '有趣': 302,\n",
       " '狗血': 303,\n",
       " '成为': 304,\n",
       " '温情': 305,\n",
       " '到底': 306,\n",
       " '搞': 307,\n",
       " '的话': 308,\n",
       " '失望': 309,\n",
       " '想起': 310,\n",
       " '整体': 311,\n",
       " '大家': 312,\n",
       " '本来': 313,\n",
       " '充满': 314,\n",
       " '幽默': 315,\n",
       " '理解': 316,\n",
       " '关系': 317,\n",
       " '不好': 318,\n",
       " '兄弟': 319,\n",
       " '成功': 320,\n",
       " '之间': 321,\n",
       " '式': 322,\n",
       " '明白': 323,\n",
       " '不同': 324,\n",
       " '效果': 325,\n",
       " '总': 326,\n",
       " '毫无': 327,\n",
       " '第一次': 328,\n",
       " '很棒': 329,\n",
       " '开头': 330,\n",
       " '相当': 331,\n",
       " '存在': 332,\n",
       " '惊喜': 333,\n",
       " '回忆': 334,\n",
       " '超级': 335,\n",
       " '怎么': 336,\n",
       " '重要': 337,\n",
       " '多少': 338,\n",
       " '文艺': 339,\n",
       " '吃': 340,\n",
       " '方式': 341,\n",
       " '真心': 342,\n",
       " '吗': 343,\n",
       " '带': 344,\n",
       " '也许': 345,\n",
       " '变成': 346,\n",
       " '比': 347,\n",
       " '做': 348,\n",
       " '垃圾': 349,\n",
       " '意义': 350,\n",
       " '好莱坞': 351,\n",
       " '味道': 352,\n",
       " '快': 353,\n",
       " '韩国': 354,\n",
       " '够': 355,\n",
       " '玩': 356,\n",
       " '漂亮': 357,\n",
       " '历史': 358,\n",
       " '全片': 359,\n",
       " '一': 360,\n",
       " '容易': 361,\n",
       " '三个': 362,\n",
       " '只是': 363,\n",
       " '依旧': 364,\n",
       " '有意思': 365,\n",
       " '设定': 366,\n",
       " '制作': 367,\n",
       " '煽情': 368,\n",
       " '当然': 369,\n",
       " '大概': 370,\n",
       " '以后': 371,\n",
       " '自然': 372,\n",
       " '想象': 373,\n",
       " '明显': 374,\n",
       " '小时候': 375,\n",
       " '名字': 376,\n",
       " '梦想': 377,\n",
       " '脸': 378,\n",
       " '不了': 379,\n",
       " '是不是': 380,\n",
       " '呵呵': 381,\n",
       " '表达': 382,\n",
       " '设计': 383,\n",
       " '打斗': 384,\n",
       " '选择': 385,\n",
       " '朋友': 386,\n",
       " '突然': 387,\n",
       " '清新': 388,\n",
       " '基本': 389,\n",
       " '四星': 390,\n",
       " '国产': 391,\n",
       " '越': 392,\n",
       " '最佳': 393,\n",
       " '不少': 394,\n",
       " '直接': 395,\n",
       " '主演': 396,\n",
       " '以前': 397,\n",
       " '为了': 398,\n",
       " '片中': 399,\n",
       " '开始': 400,\n",
       " '好好': 401,\n",
       " '意思': 402,\n",
       " '改编': 403,\n",
       " '动作片': 404,\n",
       " '整部': 405,\n",
       " '不到': 406,\n",
       " '一颗': 407,\n",
       " '暴力': 408,\n",
       " '男主角': 409,\n",
       " '元素': 410,\n",
       " '手法': 411,\n",
       " '听': 412,\n",
       " '不行': 413,\n",
       " '越来越': 414,\n",
       " '加': 415,\n",
       " '最大': 416,\n",
       " '震撼': 417,\n",
       " '豆瓣': 418,\n",
       " '几乎': 419,\n",
       " '显得': 420,\n",
       " '写': 421,\n",
       " '老套': 422,\n",
       " '政治': 423,\n",
       " '事情': 424,\n",
       " '它': 425,\n",
       " '别人': 426,\n",
       " '大片': 427,\n",
       " '台湾': 428,\n",
       " '后来': 429,\n",
       " '刻意': 430,\n",
       " '难看': 431,\n",
       " '人类': 432,\n",
       " '当时': 433,\n",
       " '高潮': 434,\n",
       " '残酷': 435,\n",
       " '好多': 436,\n",
       " '平淡': 437,\n",
       " '温暖': 438,\n",
       " '黑': 439,\n",
       " '套路': 440,\n",
       " '老师': 441,\n",
       " '棒': 442,\n",
       " '情绪': 443,\n",
       " '成长': 444,\n",
       " '心': 445,\n",
       " '相信': 446,\n",
       " '还好': 447,\n",
       " '出彩': 448,\n",
       " '更好': 449,\n",
       " '最终': 450,\n",
       " '再': 451,\n",
       " '过于': 452,\n",
       " '所谓': 453,\n",
       " '精神': 454,\n",
       " '内容': 455,\n",
       " '处理': 456,\n",
       " '前面': 457,\n",
       " '来看': 458,\n",
       " '之作': 459,\n",
       " '帅': 460,\n",
       " '不想': 461,\n",
       " '背景': 462,\n",
       " '来': 463,\n",
       " '样子': 464,\n",
       " '过去': 465,\n",
       " '些': 466,\n",
       " '内心': 467,\n",
       " '长': 468,\n",
       " '少年': 469,\n",
       " '一样': 470,\n",
       " '3d': 471,\n",
       " '反派': 472,\n",
       " '一句': 473,\n",
       " '似乎': 474,\n",
       " '为': 475,\n",
       " '推荐': 476,\n",
       " '一群': 477,\n",
       " '过程': 478,\n",
       " '有人': 479,\n",
       " '大叔': 480,\n",
       " '笑点': 481,\n",
       " '少': 482,\n",
       " '拍摄': 483,\n",
       " '美丽': 484,\n",
       " '努力': 485,\n",
       " '记忆': 486,\n",
       " '有些': 487,\n",
       " '赞': 488,\n",
       " '跟': 489,\n",
       " '桥段': 490,\n",
       " '情怀': 491,\n",
       " '想要': 492,\n",
       " '恶心': 493,\n",
       " '主旋律': 494,\n",
       " '接受': 495,\n",
       " '水准': 496,\n",
       " '此片': 497,\n",
       " '莫名其妙': 498,\n",
       " '告诉': 499,\n",
       " '没想到': 500,\n",
       " '他们': 501,\n",
       " '致敬': 502,\n",
       " '根本': 503,\n",
       " '请': 504,\n",
       " '幸福': 505,\n",
       " '至少': 506,\n",
       " '好听': 507,\n",
       " '儿子': 508,\n",
       " '拖沓': 509,\n",
       " '细腻': 510,\n",
       " '加上': 511,\n",
       " '童年': 512,\n",
       " '就算': 513,\n",
       " '这次': 514,\n",
       " '像是': 515,\n",
       " 'b': 516,\n",
       " '钱': 517,\n",
       " '女性': 518,\n",
       " '欢乐': 519,\n",
       " '跑': 520,\n",
       " '原著': 521,\n",
       " '伟大': 522,\n",
       " '呢': 523,\n",
       " '典型': 524,\n",
       " '下去': 525,\n",
       " '形象': 526,\n",
       " '游戏': 527,\n",
       " '影院': 528,\n",
       " '结构': 529,\n",
       " '警察': 530,\n",
       " '父亲': 531,\n",
       " '感受': 532,\n",
       " '成龙': 533,\n",
       " '自由': 534,\n",
       " '今天': 535,\n",
       " '结束': 536,\n",
       " '因为': 537,\n",
       " '俗套': 538,\n",
       " '港片': 539,\n",
       " '难得': 540,\n",
       " '是因为': 541,\n",
       " '配音': 542,\n",
       " '到位': 543,\n",
       " '孤独': 544,\n",
       " '分': 545,\n",
       " '继续': 546,\n",
       " '人们': 547,\n",
       " '曾经': 548,\n",
       " '梦': 549,\n",
       " '童话': 550,\n",
       " '妈': 551,\n",
       " '少女': 552,\n",
       " '十分': 553,\n",
       " '部': 554,\n",
       " '同样': 555,\n",
       " '做作': 556,\n",
       " '一般': 557,\n",
       " '气质': 558,\n",
       " '才能': 559,\n",
       " '找到': 560,\n",
       " '各种': 561,\n",
       " '反而': 562,\n",
       " '妈妈': 563,\n",
       " '水平': 564,\n",
       " '可怕': 565,\n",
       " '囧': 566,\n",
       " '一生': 567,\n",
       " '想到': 568,\n",
       " '厉害': 569,\n",
       " '用': 570,\n",
       " '意外': 571,\n",
       " '方面': 572,\n",
       " '看来': 573,\n",
       " '如此': 574,\n",
       " '小说': 575,\n",
       " '母亲': 576,\n",
       " '剧': 577,\n",
       " '吸引': 578,\n",
       " '发生': 579,\n",
       " '国家': 580,\n",
       " '行': 581,\n",
       " '讨厌': 582,\n",
       " '塑造': 583,\n",
       " '浪漫': 584,\n",
       " '女儿': 585,\n",
       " '看得': 586,\n",
       " '浪费': 587,\n",
       " '观影': 588,\n",
       " '或许': 589,\n",
       " '悲剧': 590,\n",
       " '紧凑': 591,\n",
       " '生硬': 592,\n",
       " '奥斯卡': 593,\n",
       " '从': 594,\n",
       " '影响': 595,\n",
       " '色彩': 596,\n",
       " '过瘾': 597,\n",
       " '温馨': 598,\n",
       " '爆': 599,\n",
       " '今年': 600,\n",
       " '鬼': 601,\n",
       " '字幕': 602,\n",
       " '神': 603,\n",
       " '惊艳': 604,\n",
       " '么': 605,\n",
       " '自我': 606,\n",
       " '出色': 607,\n",
       " '谁': 608,\n",
       " '到': 609,\n",
       " '最近': 610,\n",
       " '开心': 611,\n",
       " '那些': 612,\n",
       " '压抑': 613,\n",
       " '还要': 614,\n",
       " '全程': 615,\n",
       " '不管': 616,\n",
       " '改变': 617,\n",
       " '亲情': 618,\n",
       " '肯定': 619,\n",
       " '更是': 620,\n",
       " '讲述': 621,\n",
       " '视角': 622,\n",
       " '上映': 623,\n",
       " '哎': 624,\n",
       " '片尾': 625,\n",
       " '男女': 626,\n",
       " '黑暗': 627,\n",
       " '爸爸': 628,\n",
       " '坚持': 629,\n",
       " '多么': 630,\n",
       " '热血': 631,\n",
       " '未来': 632,\n",
       " '狗': 633,\n",
       " '新意': 634,\n",
       " '大师': 635,\n",
       " '低': 636,\n",
       " '讽刺': 637,\n",
       " '青春片': 638,\n",
       " '着': 639,\n",
       " '中间': 640,\n",
       " '刻画': 641,\n",
       " '杀': 642,\n",
       " '声音': 643,\n",
       " '不用': 644,\n",
       " '还有': 645,\n",
       " '印度': 646,\n",
       " '文化': 647,\n",
       " '电视剧': 648,\n",
       " '混乱': 649,\n",
       " '的确': 650,\n",
       " '动人': 651,\n",
       " '小孩': 652,\n",
       " '还行': 653,\n",
       " '更加': 654,\n",
       " '冲突': 655,\n",
       " '属于': 656,\n",
       " '两星': 657,\n",
       " '语言': 658,\n",
       " '难': 659,\n",
       " '叫': 660,\n",
       " '只有': 661,\n",
       " '经历': 662,\n",
       " '智商': 663,\n",
       " '力量': 664,\n",
       " '宗教': 665,\n",
       " '一切': 666,\n",
       " '心理': 667,\n",
       " '轻松': 668,\n",
       " '美女': 669,\n",
       " '電影': 670,\n",
       " '眼睛': 671,\n",
       " '黑色幽默': 672,\n",
       " '空间': 673,\n",
       " '好笑': 674,\n",
       " '心里': 675,\n",
       " '科幻': 676,\n",
       " '大陆': 677,\n",
       " '明星': 678,\n",
       " '冲着': 679,\n",
       " '悬疑': 680,\n",
       " '平庸': 681,\n",
       " '死亡': 682,\n",
       " '续集': 683,\n",
       " '见': 684,\n",
       " '岁': 685,\n",
       " '相比': 686,\n",
       " '线': 687,\n",
       " '纯粹': 688,\n",
       " '忘': 689,\n",
       " '造型': 690,\n",
       " '必须': 691,\n",
       " '技术': 692,\n",
       " '评分': 693,\n",
       " '别': 694,\n",
       " '十足': 695,\n",
       " '掉': 696,\n",
       " '完整': 697,\n",
       " '本': 698,\n",
       " '不知': 699,\n",
       " '流畅': 700,\n",
       " '命运': 701,\n",
       " '明明': 702,\n",
       " '演得': 703,\n",
       " '失去': 704,\n",
       " '配角': 705,\n",
       " '看起来': 706,\n",
       " '主要': 707,\n",
       " '拯救': 708,\n",
       " '枪战': 709,\n",
       " '后半段': 710,\n",
       " '强大': 711,\n",
       " '能够': 712,\n",
       " '事件': 713,\n",
       " '略': 714,\n",
       " '疯狂': 715,\n",
       " '不得不': 716,\n",
       " '长镜头': 717,\n",
       " '与': 718,\n",
       " '虽然': 719,\n",
       " '渣': 720,\n",
       " '第二部': 721,\n",
       " '创意': 722,\n",
       " '失败': 723,\n",
       " '太多': 724,\n",
       " '魅力': 725,\n",
       " '艺术': 726,\n",
       " '面对': 727,\n",
       " '一遍': 728,\n",
       " '对白': 729,\n",
       " '奇怪': 730,\n",
       " '估计': 731,\n",
       " '超': 732,\n",
       " '毕竟': 733,\n",
       " '看不下去': 734,\n",
       " '正': 735,\n",
       " '在于': 736,\n",
       " '西部片': 737,\n",
       " '二': 738,\n",
       " '功夫': 739,\n",
       " '乱': 740,\n",
       " '多年': 741,\n",
       " '不断': 742,\n",
       " '海报': 743,\n",
       " '华丽': 744,\n",
       " '假': 745,\n",
       " '展现': 746,\n",
       " '唉': 747,\n",
       " '梗': 748,\n",
       " '女孩': 749,\n",
       " '发展': 750,\n",
       " '2': 751,\n",
       " '强': 752,\n",
       " '每次': 753,\n",
       " '城市': 754,\n",
       " '思考': 755,\n",
       " '得到': 756,\n",
       " '哥哥': 757,\n",
       " '用心': 758,\n",
       " '下来': 759,\n",
       " '女神': 760,\n",
       " '信仰': 761,\n",
       " '夸张': 762,\n",
       " '放': 763,\n",
       " '广告': 764,\n",
       " '传统': 765,\n",
       " '弱': 766,\n",
       " '睡着': 767,\n",
       " '刺激': 768,\n",
       " '表情': 769,\n",
       " '反正': 770,\n",
       " '普通': 771,\n",
       " '气氛': 772,\n",
       " '认为': 773,\n",
       " '无奈': 774,\n",
       " '不算': 775,\n",
       " '能力': 776,\n",
       " '片名': 777,\n",
       " '痛苦': 778,\n",
       " '复杂': 779,\n",
       " '形式': 780,\n",
       " '比如': 781,\n",
       " '角度': 782,\n",
       " '天才': 783,\n",
       " '舒服': 784,\n",
       " '为什么': 785,\n",
       " '瞎': 786,\n",
       " '槽': 787,\n",
       " '吐': 788,\n",
       " '犯罪': 789,\n",
       " '黑色': 790,\n",
       " '一半': 791,\n",
       " '杀手': 792,\n",
       " '始终': 793,\n",
       " '想象力': 794,\n",
       " '恐怖': 795,\n",
       " '戏份': 796,\n",
       " '动画片': 797,\n",
       " '狼': 798,\n",
       " '拍出': 799,\n",
       " '反转': 800,\n",
       " '身上': 801,\n",
       " '想法': 802,\n",
       " '有种': 803,\n",
       " '35': 804,\n",
       " '武士': 805,\n",
       " '小女孩': 806,\n",
       " '法国': 807,\n",
       " '一天': 808,\n",
       " '前半段': 809,\n",
       " '打动': 810,\n",
       " '程度': 811,\n",
       " '高': 812,\n",
       " '矫情': 813,\n",
       " '变': 814,\n",
       " '比起': 815,\n",
       " '年度': 816,\n",
       " '不再': 817,\n",
       " '治愈': 818,\n",
       " '血腥': 819,\n",
       " '三': 820,\n",
       " '风景': 821,\n",
       " '绝望': 822,\n",
       " '嗯': 823,\n",
       " '仍然': 824,\n",
       " '遗憾': 825,\n",
       " '足够': 826,\n",
       " '长大': 827,\n",
       " '却是': 828,\n",
       " '原因': 829,\n",
       " '超越': 830,\n",
       " '美的': 831,\n",
       " '铺垫': 832,\n",
       " '无比': 833,\n",
       " '太过': 834,\n",
       " '总体': 835,\n",
       " '眼泪': 836,\n",
       " '天': 837,\n",
       " '性格': 838,\n",
       " '很大': 839,\n",
       " '评价': 840,\n",
       " 'x': 841,\n",
       " '尼玛': 842,\n",
       " '类似': 843,\n",
       " '化': 844,\n",
       " '紧张': 845,\n",
       " '票房': 846,\n",
       " '颜值': 847,\n",
       " '变得': 848,\n",
       " '模仿': 849,\n",
       " '字': 850,\n",
       " '间': 851,\n",
       " '爆米花': 852,\n",
       " '影子': 853,\n",
       " '反': 854,\n",
       " '啊啊啊': 855,\n",
       " '酱油': 856,\n",
       " '带来': 857,\n",
       " '视觉': 858,\n",
       " '彩蛋': 859,\n",
       " '矛盾': 860,\n",
       " '版本': 861,\n",
       " '心中': 862,\n",
       " '评论': 863,\n",
       " '片段': 864,\n",
       " '演绎': 865,\n",
       " '演出': 866,\n",
       " '商业': 867,\n",
       " '三部曲': 868,\n",
       " '功力': 869,\n",
       " '仍': 870,\n",
       " '猜': 871,\n",
       " '两部': 872,\n",
       " '人心': 873,\n",
       " '电视': 874,\n",
       " '快乐': 875,\n",
       " '影像': 876,\n",
       " '家': 877,\n",
       " '氛围': 878,\n",
       " '哈哈哈哈': 879,\n",
       " '难道': 880,\n",
       " '看不懂': 881,\n",
       " '全部': 882,\n",
       " '精致': 883,\n",
       " '了解': 884,\n",
       " '屎': 885,\n",
       " '认真': 886,\n",
       " '眼神': 887,\n",
       " '悲伤': 888,\n",
       " '科恩': 889,\n",
       " '商业片': 890,\n",
       " '第一': 891,\n",
       " '非': 892,\n",
       " '亦': 893,\n",
       " '說': 894,\n",
       " '欣赏': 895,\n",
       " '做到': 896,\n",
       " '飞机': 897,\n",
       " '荒诞': 898,\n",
       " '过': 899,\n",
       " '穿越': 900,\n",
       " '强烈': 901,\n",
       " '灵魂': 902,\n",
       " '黑帮': 903,\n",
       " '标准': 904,\n",
       " '追求': 905,\n",
       " '值得一看': 906,\n",
       " '杨': 907,\n",
       " '演戏': 908,\n",
       " '差点': 909,\n",
       " '再次': 910,\n",
       " '吐槽': 911,\n",
       " '不可': 912,\n",
       " '装': 913,\n",
       " '上': 914,\n",
       " '路': 915,\n",
       " '缺乏': 916,\n",
       " '看似': 917,\n",
       " '许多': 918,\n",
       " '穿': 919,\n",
       " '爱情片': 920,\n",
       " '熟悉': 921,\n",
       " '上帝': 922,\n",
       " '片儿': 923,\n",
       " '扯': 924,\n",
       " '诚意': 925,\n",
       " '对话': 926,\n",
       " '之外': 927,\n",
       " '不太': 928,\n",
       " '俩': 929,\n",
       " '站': 930,\n",
       " '忘记': 931,\n",
       " '姑娘': 932,\n",
       " '设置': 933,\n",
       " '杀人': 934,\n",
       " 'tv': 935,\n",
       " '没看': 936,\n",
       " '影帝': 937,\n",
       " '1': 938,\n",
       " '跳': 939,\n",
       " '回来': 940,\n",
       " '彻底': 941,\n",
       " '對': 942,\n",
       " '回到': 943,\n",
       " '不足': 944,\n",
       " '活着': 945,\n",
       " '般的': 946,\n",
       " '买': 947,\n",
       " '有着': 948,\n",
       " '所以': 949,\n",
       " '看点': 950,\n",
       " '成本': 951,\n",
       " '文艺片': 952,\n",
       " '质量': 953,\n",
       " '戏剧': 954,\n",
       " '国内': 955,\n",
       " '粗糙': 956,\n",
       " '并': 957,\n",
       " '青年': 958,\n",
       " '小朋友': 959,\n",
       " '结果': 960,\n",
       " '如果': 961,\n",
       " '解释': 962,\n",
       " '出戏': 963,\n",
       " '段落': 964,\n",
       " '看出': 965,\n",
       " '观看': 966,\n",
       " '一如既往': 967,\n",
       " '冗长': 968,\n",
       " '可怜': 969,\n",
       " '支持': 970,\n",
       " '白': 971,\n",
       " '娱乐': 972,\n",
       " '90': 973,\n",
       " '长得': 974,\n",
       " '拍成': 975,\n",
       " '类': 976,\n",
       " '怪': 977,\n",
       " '使': 978,\n",
       " '瞬间': 979,\n",
       " '复仇': 980,\n",
       " '纠结': 981,\n",
       " '3': 982,\n",
       " '放在': 983,\n",
       " '中规中矩': 984,\n",
       " '喜剧片': 985,\n",
       " '一般般': 986,\n",
       " '毁': 987,\n",
       " '动物': 988,\n",
       " '正常': 989,\n",
       " '大战': 990,\n",
       " '心情': 991,\n",
       " '歌': 992,\n",
       " '模式': 993,\n",
       " '一幕': 994,\n",
       " '浮夸': 995,\n",
       " '差不多': 996,\n",
       " '状态': 997,\n",
       " '仿佛': 998,\n",
       " '英国': 999,\n",
       " 'bug': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161902"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261496"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count  # whole corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29999, 247, 17532]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X_train )  # 30000 以内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261496"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen,padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   493,    34,   788],\n",
       "       [    0,     0,     0, ...,    54,  2732,  8241],\n",
       "       [    0,     0,     0, ..., 10219,   204,  1655],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    22,   104,    14],\n",
       "       [    0,     0,     0, ...,    83,     1,   525],\n",
       "       [    0,     0,     0, ...,  4404,  3722,   493]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261496, 50)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 150)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "embedding_matrix .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "word_vectors = fasttext.load_model(\"fast2.bin\")  # 导入fst模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = word_vectors.get_word_vector(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 150)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)   #160\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(5, activation=\"sigmoid\")(conc)\n",
    "    print(outp.shape)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,   39, 7763,\n",
       "        167,   71,    1,   16,   54, 3677])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tra[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5)\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 150)      4500000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 50, 150)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 160)      111360      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 160)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 160)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 320)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            1926        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 4,613,286\n",
      "Trainable params: 4,613,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 248421 samples, validate on 13075 samples\n",
      "Epoch 1/2\n",
      "248421/248421 [==============================] - 1152s 5ms/sample - loss: 0.2943 - accuracy: 0.8612 - val_loss: 0.3018 - val_accuracy: 0.8569\n",
      "Epoch 2/2\n",
      " 65344/248421 [======>.......................] - ETA: 14:28 - loss: 0.2715 - accuracy: 0.8753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-9bb388cf359f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mRocAuc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRocAucEvaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[0;32m    173\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m       \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[1;34m(self, step, mode, size)\u001b[0m\n\u001b[0;32m    699\u001b[0m         self.callbacks._call_batch_hook(\n\u001b[0;32m    700\u001b[0m             mode, 'end', step, batch_logs)\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    389\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    390\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准确率感觉到88 左右。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248421, 50)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248421, 5)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13075, 5)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
