{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    #shape = hidden.get_shape().as_list()\n",
    "   # print(\"*****\",shape)  # 14*14*16\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    #print(\"####\",shape)   7*7*16\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 37
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63292,
     "status": "ok",
     "timestamp": 1446658966251,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "noKFb2UovVFR",
    "outputId": "28941338-2ef9-4088-8bd1-44295661e628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "the index is : 0\n",
      "Minibatch loss at step 0: 4.290326\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 11.0%\n",
      "the index is : 16\n",
      "the index is : 32\n",
      "the index is : 48\n",
      "the index is : 64\n",
      "the index is : 80\n",
      "the index is : 96\n",
      "the index is : 112\n",
      "the index is : 128\n",
      "the index is : 144\n",
      "the index is : 160\n",
      "the index is : 176\n",
      "the index is : 192\n",
      "the index is : 208\n",
      "the index is : 224\n",
      "the index is : 240\n",
      "the index is : 256\n",
      "the index is : 272\n",
      "the index is : 288\n",
      "the index is : 304\n",
      "the index is : 320\n",
      "the index is : 336\n",
      "the index is : 352\n",
      "the index is : 368\n",
      "the index is : 384\n",
      "the index is : 400\n",
      "the index is : 416\n",
      "the index is : 432\n",
      "the index is : 448\n",
      "the index is : 464\n",
      "the index is : 480\n",
      "the index is : 496\n",
      "the index is : 512\n",
      "the index is : 528\n",
      "the index is : 544\n",
      "the index is : 560\n",
      "the index is : 576\n",
      "the index is : 592\n",
      "the index is : 608\n",
      "the index is : 624\n",
      "the index is : 640\n",
      "the index is : 656\n",
      "the index is : 672\n",
      "the index is : 688\n",
      "the index is : 704\n",
      "the index is : 720\n",
      "the index is : 736\n",
      "the index is : 752\n",
      "the index is : 768\n",
      "the index is : 784\n",
      "the index is : 800\n",
      "Minibatch loss at step 50: 1.129706\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 57.0%\n",
      "the index is : 816\n",
      "the index is : 832\n",
      "the index is : 848\n",
      "the index is : 864\n",
      "the index is : 880\n",
      "the index is : 896\n",
      "the index is : 912\n",
      "the index is : 928\n",
      "the index is : 944\n",
      "the index is : 960\n",
      "the index is : 976\n",
      "the index is : 992\n",
      "the index is : 1008\n",
      "the index is : 1024\n",
      "the index is : 1040\n",
      "the index is : 1056\n",
      "the index is : 1072\n",
      "the index is : 1088\n",
      "the index is : 1104\n",
      "the index is : 1120\n",
      "the index is : 1136\n",
      "the index is : 1152\n",
      "the index is : 1168\n",
      "the index is : 1184\n",
      "the index is : 1200\n",
      "the index is : 1216\n",
      "the index is : 1232\n",
      "the index is : 1248\n",
      "the index is : 1264\n",
      "the index is : 1280\n",
      "the index is : 1296\n",
      "the index is : 1312\n",
      "the index is : 1328\n",
      "the index is : 1344\n",
      "the index is : 1360\n",
      "the index is : 1376\n",
      "the index is : 1392\n",
      "the index is : 1408\n",
      "the index is : 1424\n",
      "the index is : 1440\n",
      "the index is : 1456\n",
      "the index is : 1472\n",
      "the index is : 1488\n",
      "the index is : 1504\n",
      "the index is : 1520\n",
      "the index is : 1536\n",
      "the index is : 1552\n",
      "the index is : 1568\n",
      "the index is : 1584\n",
      "the index is : 1600\n",
      "Minibatch loss at step 100: 1.243945\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 72.1%\n",
      "the index is : 1616\n",
      "the index is : 1632\n",
      "the index is : 1648\n",
      "the index is : 1664\n",
      "the index is : 1680\n",
      "the index is : 1696\n",
      "the index is : 1712\n",
      "the index is : 1728\n",
      "the index is : 1744\n",
      "the index is : 1760\n",
      "the index is : 1776\n",
      "the index is : 1792\n",
      "the index is : 1808\n",
      "the index is : 1824\n",
      "the index is : 1840\n",
      "the index is : 1856\n",
      "the index is : 1872\n",
      "the index is : 1888\n",
      "the index is : 1904\n",
      "the index is : 1920\n",
      "the index is : 1936\n",
      "the index is : 1952\n",
      "the index is : 1968\n",
      "the index is : 1984\n",
      "the index is : 2000\n",
      "the index is : 2016\n",
      "the index is : 2032\n",
      "the index is : 2048\n",
      "the index is : 2064\n",
      "the index is : 2080\n",
      "the index is : 2096\n",
      "the index is : 2112\n",
      "the index is : 2128\n",
      "the index is : 2144\n",
      "the index is : 2160\n",
      "the index is : 2176\n",
      "the index is : 2192\n",
      "the index is : 2208\n",
      "the index is : 2224\n",
      "the index is : 2240\n",
      "the index is : 2256\n",
      "the index is : 2272\n",
      "the index is : 2288\n",
      "the index is : 2304\n",
      "the index is : 2320\n",
      "the index is : 2336\n",
      "the index is : 2352\n",
      "the index is : 2368\n",
      "the index is : 2384\n",
      "the index is : 2400\n",
      "Minibatch loss at step 150: 1.190173\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.2%\n",
      "the index is : 2416\n",
      "the index is : 2432\n",
      "the index is : 2448\n",
      "the index is : 2464\n",
      "the index is : 2480\n",
      "the index is : 2496\n",
      "the index is : 2512\n",
      "the index is : 2528\n",
      "the index is : 2544\n",
      "the index is : 2560\n",
      "the index is : 2576\n",
      "the index is : 2592\n",
      "the index is : 2608\n",
      "the index is : 2624\n",
      "the index is : 2640\n",
      "the index is : 2656\n",
      "the index is : 2672\n",
      "the index is : 2688\n",
      "the index is : 2704\n",
      "the index is : 2720\n",
      "the index is : 2736\n",
      "the index is : 2752\n",
      "the index is : 2768\n",
      "the index is : 2784\n",
      "the index is : 2800\n",
      "the index is : 2816\n",
      "the index is : 2832\n",
      "the index is : 2848\n",
      "the index is : 2864\n",
      "the index is : 2880\n",
      "the index is : 2896\n",
      "the index is : 2912\n",
      "the index is : 2928\n",
      "the index is : 2944\n",
      "the index is : 2960\n",
      "the index is : 2976\n",
      "the index is : 2992\n",
      "the index is : 3008\n",
      "the index is : 3024\n",
      "the index is : 3040\n",
      "the index is : 3056\n",
      "the index is : 3072\n",
      "the index is : 3088\n",
      "the index is : 3104\n",
      "the index is : 3120\n",
      "the index is : 3136\n",
      "the index is : 3152\n",
      "the index is : 3168\n",
      "the index is : 3184\n",
      "the index is : 3200\n",
      "Minibatch loss at step 200: 1.190870\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 74.3%\n",
      "the index is : 3216\n",
      "the index is : 3232\n",
      "the index is : 3248\n",
      "the index is : 3264\n",
      "the index is : 3280\n",
      "the index is : 3296\n",
      "the index is : 3312\n",
      "the index is : 3328\n",
      "the index is : 3344\n",
      "the index is : 3360\n",
      "the index is : 3376\n",
      "the index is : 3392\n",
      "the index is : 3408\n",
      "the index is : 3424\n",
      "the index is : 3440\n",
      "the index is : 3456\n",
      "the index is : 3472\n",
      "the index is : 3488\n",
      "the index is : 3504\n",
      "the index is : 3520\n",
      "the index is : 3536\n",
      "the index is : 3552\n",
      "the index is : 3568\n",
      "the index is : 3584\n",
      "the index is : 3600\n",
      "the index is : 3616\n",
      "the index is : 3632\n",
      "the index is : 3648\n",
      "the index is : 3664\n",
      "the index is : 3680\n",
      "the index is : 3696\n",
      "the index is : 3712\n",
      "the index is : 3728\n",
      "the index is : 3744\n",
      "the index is : 3760\n",
      "the index is : 3776\n",
      "the index is : 3792\n",
      "the index is : 3808\n",
      "the index is : 3824\n",
      "the index is : 3840\n",
      "the index is : 3856\n",
      "the index is : 3872\n",
      "the index is : 3888\n",
      "the index is : 3904\n",
      "the index is : 3920\n",
      "the index is : 3936\n",
      "the index is : 3952\n",
      "the index is : 3968\n",
      "the index is : 3984\n",
      "the index is : 4000\n",
      "Minibatch loss at step 250: 0.419107\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.7%\n",
      "the index is : 4016\n",
      "the index is : 4032\n",
      "the index is : 4048\n",
      "the index is : 4064\n",
      "the index is : 4080\n",
      "the index is : 4096\n",
      "the index is : 4112\n",
      "the index is : 4128\n",
      "the index is : 4144\n",
      "the index is : 4160\n",
      "the index is : 4176\n",
      "the index is : 4192\n",
      "the index is : 4208\n",
      "the index is : 4224\n",
      "the index is : 4240\n",
      "the index is : 4256\n",
      "the index is : 4272\n",
      "the index is : 4288\n",
      "the index is : 4304\n",
      "the index is : 4320\n",
      "the index is : 4336\n",
      "the index is : 4352\n",
      "the index is : 4368\n",
      "the index is : 4384\n",
      "the index is : 4400\n",
      "the index is : 4416\n",
      "the index is : 4432\n",
      "the index is : 4448\n",
      "the index is : 4464\n",
      "the index is : 4480\n",
      "the index is : 4496\n",
      "the index is : 4512\n",
      "the index is : 4528\n",
      "the index is : 4544\n",
      "the index is : 4560\n",
      "the index is : 4576\n",
      "the index is : 4592\n",
      "the index is : 4608\n",
      "the index is : 4624\n",
      "the index is : 4640\n",
      "the index is : 4656\n",
      "the index is : 4672\n",
      "the index is : 4688\n",
      "the index is : 4704\n",
      "the index is : 4720\n",
      "the index is : 4736\n",
      "the index is : 4752\n",
      "the index is : 4768\n",
      "the index is : 4784\n",
      "the index is : 4800\n",
      "Minibatch loss at step 300: 0.907282\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.7%\n",
      "the index is : 4816\n",
      "the index is : 4832\n",
      "the index is : 4848\n",
      "the index is : 4864\n",
      "the index is : 4880\n",
      "the index is : 4896\n",
      "the index is : 4912\n",
      "the index is : 4928\n",
      "the index is : 4944\n",
      "the index is : 4960\n",
      "the index is : 4976\n",
      "the index is : 4992\n",
      "the index is : 5008\n",
      "the index is : 5024\n",
      "the index is : 5040\n",
      "the index is : 5056\n",
      "the index is : 5072\n",
      "the index is : 5088\n",
      "the index is : 5104\n",
      "the index is : 5120\n",
      "the index is : 5136\n",
      "the index is : 5152\n",
      "the index is : 5168\n",
      "the index is : 5184\n",
      "the index is : 5200\n",
      "the index is : 5216\n",
      "the index is : 5232\n",
      "the index is : 5248\n",
      "the index is : 5264\n",
      "the index is : 5280\n",
      "the index is : 5296\n",
      "the index is : 5312\n",
      "the index is : 5328\n",
      "the index is : 5344\n",
      "the index is : 5360\n",
      "the index is : 5376\n",
      "the index is : 5392\n",
      "the index is : 5408\n",
      "the index is : 5424\n",
      "the index is : 5440\n",
      "the index is : 5456\n",
      "the index is : 5472\n",
      "the index is : 5488\n",
      "the index is : 5504\n",
      "the index is : 5520\n",
      "the index is : 5536\n",
      "the index is : 5552\n",
      "the index is : 5568\n",
      "the index is : 5584\n",
      "the index is : 5600\n",
      "Minibatch loss at step 350: 0.546205\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.7%\n",
      "the index is : 5616\n",
      "the index is : 5632\n",
      "the index is : 5648\n",
      "the index is : 5664\n",
      "the index is : 5680\n",
      "the index is : 5696\n",
      "the index is : 5712\n",
      "the index is : 5728\n",
      "the index is : 5744\n",
      "the index is : 5760\n",
      "the index is : 5776\n",
      "the index is : 5792\n",
      "the index is : 5808\n",
      "the index is : 5824\n",
      "the index is : 5840\n",
      "the index is : 5856\n",
      "the index is : 5872\n",
      "the index is : 5888\n",
      "the index is : 5904\n",
      "the index is : 5920\n",
      "the index is : 5936\n",
      "the index is : 5952\n",
      "the index is : 5968\n",
      "the index is : 5984\n",
      "the index is : 6000\n",
      "the index is : 6016\n",
      "the index is : 6032\n",
      "the index is : 6048\n",
      "the index is : 6064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index is : 6080\n",
      "the index is : 6096\n",
      "the index is : 6112\n",
      "the index is : 6128\n",
      "the index is : 6144\n",
      "the index is : 6160\n",
      "the index is : 6176\n",
      "the index is : 6192\n",
      "the index is : 6208\n",
      "the index is : 6224\n",
      "the index is : 6240\n",
      "the index is : 6256\n",
      "the index is : 6272\n",
      "the index is : 6288\n",
      "the index is : 6304\n",
      "the index is : 6320\n",
      "the index is : 6336\n",
      "the index is : 6352\n",
      "the index is : 6368\n",
      "the index is : 6384\n",
      "the index is : 6400\n",
      "Minibatch loss at step 400: 0.190827\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 82.0%\n",
      "the index is : 6416\n",
      "the index is : 6432\n",
      "the index is : 6448\n",
      "the index is : 6464\n",
      "the index is : 6480\n",
      "the index is : 6496\n",
      "the index is : 6512\n",
      "the index is : 6528\n",
      "the index is : 6544\n",
      "the index is : 6560\n",
      "the index is : 6576\n",
      "the index is : 6592\n",
      "the index is : 6608\n",
      "the index is : 6624\n",
      "the index is : 6640\n",
      "the index is : 6656\n",
      "the index is : 6672\n",
      "the index is : 6688\n",
      "the index is : 6704\n",
      "the index is : 6720\n",
      "the index is : 6736\n",
      "the index is : 6752\n",
      "the index is : 6768\n",
      "the index is : 6784\n",
      "the index is : 6800\n",
      "the index is : 6816\n",
      "the index is : 6832\n",
      "the index is : 6848\n",
      "the index is : 6864\n",
      "the index is : 6880\n",
      "the index is : 6896\n",
      "the index is : 6912\n",
      "the index is : 6928\n",
      "the index is : 6944\n",
      "the index is : 6960\n",
      "the index is : 6976\n",
      "the index is : 6992\n",
      "the index is : 7008\n",
      "the index is : 7024\n",
      "the index is : 7040\n",
      "the index is : 7056\n",
      "the index is : 7072\n",
      "the index is : 7088\n",
      "the index is : 7104\n",
      "the index is : 7120\n",
      "the index is : 7136\n",
      "the index is : 7152\n",
      "the index is : 7168\n",
      "the index is : 7184\n",
      "the index is : 7200\n",
      "Minibatch loss at step 450: 0.523900\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "the index is : 7216\n",
      "the index is : 7232\n",
      "the index is : 7248\n",
      "the index is : 7264\n",
      "the index is : 7280\n",
      "the index is : 7296\n",
      "the index is : 7312\n",
      "the index is : 7328\n",
      "the index is : 7344\n",
      "the index is : 7360\n",
      "the index is : 7376\n",
      "the index is : 7392\n",
      "the index is : 7408\n",
      "the index is : 7424\n",
      "the index is : 7440\n",
      "the index is : 7456\n",
      "the index is : 7472\n",
      "the index is : 7488\n",
      "the index is : 7504\n",
      "the index is : 7520\n",
      "the index is : 7536\n",
      "the index is : 7552\n",
      "the index is : 7568\n",
      "the index is : 7584\n",
      "the index is : 7600\n",
      "the index is : 7616\n",
      "the index is : 7632\n",
      "the index is : 7648\n",
      "the index is : 7664\n",
      "the index is : 7680\n",
      "the index is : 7696\n",
      "the index is : 7712\n",
      "the index is : 7728\n",
      "the index is : 7744\n",
      "the index is : 7760\n",
      "the index is : 7776\n",
      "the index is : 7792\n",
      "the index is : 7808\n",
      "the index is : 7824\n",
      "the index is : 7840\n",
      "the index is : 7856\n",
      "the index is : 7872\n",
      "the index is : 7888\n",
      "the index is : 7904\n",
      "the index is : 7920\n",
      "the index is : 7936\n",
      "the index is : 7952\n",
      "the index is : 7968\n",
      "the index is : 7984\n",
      "the index is : 8000\n",
      "Minibatch loss at step 500: 0.854537\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.5%\n",
      "the index is : 8016\n",
      "the index is : 8032\n",
      "the index is : 8048\n",
      "the index is : 8064\n",
      "the index is : 8080\n",
      "the index is : 8096\n",
      "the index is : 8112\n",
      "the index is : 8128\n",
      "the index is : 8144\n",
      "the index is : 8160\n",
      "the index is : 8176\n",
      "the index is : 8192\n",
      "the index is : 8208\n",
      "the index is : 8224\n",
      "the index is : 8240\n",
      "the index is : 8256\n",
      "the index is : 8272\n",
      "the index is : 8288\n",
      "the index is : 8304\n",
      "the index is : 8320\n",
      "the index is : 8336\n",
      "the index is : 8352\n",
      "the index is : 8368\n",
      "the index is : 8384\n",
      "the index is : 8400\n",
      "the index is : 8416\n",
      "the index is : 8432\n",
      "the index is : 8448\n",
      "the index is : 8464\n",
      "the index is : 8480\n",
      "the index is : 8496\n",
      "the index is : 8512\n",
      "the index is : 8528\n",
      "the index is : 8544\n",
      "the index is : 8560\n",
      "the index is : 8576\n",
      "the index is : 8592\n",
      "the index is : 8608\n",
      "the index is : 8624\n",
      "the index is : 8640\n",
      "the index is : 8656\n",
      "the index is : 8672\n",
      "the index is : 8688\n",
      "the index is : 8704\n",
      "the index is : 8720\n",
      "the index is : 8736\n",
      "the index is : 8752\n",
      "the index is : 8768\n",
      "the index is : 8784\n",
      "the index is : 8800\n",
      "Minibatch loss at step 550: 0.410117\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.5%\n",
      "the index is : 8816\n",
      "the index is : 8832\n",
      "the index is : 8848\n",
      "the index is : 8864\n",
      "the index is : 8880\n",
      "the index is : 8896\n",
      "the index is : 8912\n",
      "the index is : 8928\n",
      "the index is : 8944\n",
      "the index is : 8960\n",
      "the index is : 8976\n",
      "the index is : 8992\n",
      "the index is : 9008\n",
      "the index is : 9024\n",
      "the index is : 9040\n",
      "the index is : 9056\n",
      "the index is : 9072\n",
      "the index is : 9088\n",
      "the index is : 9104\n",
      "the index is : 9120\n",
      "the index is : 9136\n",
      "the index is : 9152\n",
      "the index is : 9168\n",
      "the index is : 9184\n",
      "the index is : 9200\n",
      "the index is : 9216\n",
      "the index is : 9232\n",
      "the index is : 9248\n",
      "the index is : 9264\n",
      "the index is : 9280\n",
      "the index is : 9296\n",
      "the index is : 9312\n",
      "the index is : 9328\n",
      "the index is : 9344\n",
      "the index is : 9360\n",
      "the index is : 9376\n",
      "the index is : 9392\n",
      "the index is : 9408\n",
      "the index is : 9424\n",
      "the index is : 9440\n",
      "the index is : 9456\n",
      "the index is : 9472\n",
      "the index is : 9488\n",
      "the index is : 9504\n",
      "the index is : 9520\n",
      "the index is : 9536\n",
      "the index is : 9552\n",
      "the index is : 9568\n",
      "the index is : 9584\n",
      "the index is : 9600\n",
      "Minibatch loss at step 600: 0.276229\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.4%\n",
      "the index is : 9616\n",
      "the index is : 9632\n",
      "the index is : 9648\n",
      "the index is : 9664\n",
      "the index is : 9680\n",
      "the index is : 9696\n",
      "the index is : 9712\n",
      "the index is : 9728\n",
      "the index is : 9744\n",
      "the index is : 9760\n",
      "the index is : 9776\n",
      "the index is : 9792\n",
      "the index is : 9808\n",
      "the index is : 9824\n",
      "the index is : 9840\n",
      "the index is : 9856\n",
      "the index is : 9872\n",
      "the index is : 9888\n",
      "the index is : 9904\n",
      "the index is : 9920\n",
      "the index is : 9936\n",
      "the index is : 9952\n",
      "the index is : 9968\n",
      "the index is : 9984\n",
      "the index is : 10000\n",
      "the index is : 10016\n",
      "the index is : 10032\n",
      "the index is : 10048\n",
      "the index is : 10064\n",
      "the index is : 10080\n",
      "the index is : 10096\n",
      "the index is : 10112\n",
      "the index is : 10128\n",
      "the index is : 10144\n",
      "the index is : 10160\n",
      "the index is : 10176\n",
      "the index is : 10192\n",
      "the index is : 10208\n",
      "the index is : 10224\n",
      "the index is : 10240\n",
      "the index is : 10256\n",
      "the index is : 10272\n",
      "the index is : 10288\n",
      "the index is : 10304\n",
      "the index is : 10320\n",
      "the index is : 10336\n",
      "the index is : 10352\n",
      "the index is : 10368\n",
      "the index is : 10384\n",
      "the index is : 10400\n",
      "Minibatch loss at step 650: 0.108901\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 82.7%\n",
      "the index is : 10416\n",
      "the index is : 10432\n",
      "the index is : 10448\n",
      "the index is : 10464\n",
      "the index is : 10480\n",
      "the index is : 10496\n",
      "the index is : 10512\n",
      "the index is : 10528\n",
      "the index is : 10544\n",
      "the index is : 10560\n",
      "the index is : 10576\n",
      "the index is : 10592\n",
      "the index is : 10608\n",
      "the index is : 10624\n",
      "the index is : 10640\n",
      "the index is : 10656\n",
      "the index is : 10672\n",
      "the index is : 10688\n",
      "the index is : 10704\n",
      "the index is : 10720\n",
      "the index is : 10736\n",
      "the index is : 10752\n",
      "the index is : 10768\n",
      "the index is : 10784\n",
      "the index is : 10800\n",
      "the index is : 10816\n",
      "the index is : 10832\n",
      "the index is : 10848\n",
      "the index is : 10864\n",
      "the index is : 10880\n",
      "the index is : 10896\n",
      "the index is : 10912\n",
      "the index is : 10928\n",
      "the index is : 10944\n",
      "the index is : 10960\n",
      "the index is : 10976\n",
      "the index is : 10992\n",
      "the index is : 11008\n",
      "the index is : 11024\n",
      "the index is : 11040\n",
      "the index is : 11056\n",
      "the index is : 11072\n",
      "the index is : 11088\n",
      "the index is : 11104\n",
      "the index is : 11120\n",
      "the index is : 11136\n",
      "the index is : 11152\n",
      "the index is : 11168\n",
      "the index is : 11184\n",
      "the index is : 11200\n",
      "Minibatch loss at step 700: 0.669145\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.4%\n",
      "the index is : 11216\n",
      "the index is : 11232\n",
      "the index is : 11248\n",
      "the index is : 11264\n",
      "the index is : 11280\n",
      "the index is : 11296\n",
      "the index is : 11312\n",
      "the index is : 11328\n",
      "the index is : 11344\n",
      "the index is : 11360\n",
      "the index is : 11376\n",
      "the index is : 11392\n",
      "the index is : 11408\n",
      "the index is : 11424\n",
      "the index is : 11440\n",
      "the index is : 11456\n",
      "the index is : 11472\n",
      "the index is : 11488\n",
      "the index is : 11504\n",
      "the index is : 11520\n",
      "the index is : 11536\n",
      "the index is : 11552\n",
      "the index is : 11568\n",
      "the index is : 11584\n",
      "the index is : 11600\n",
      "the index is : 11616\n",
      "the index is : 11632\n",
      "the index is : 11648\n",
      "the index is : 11664\n",
      "the index is : 11680\n",
      "the index is : 11696\n",
      "the index is : 11712\n",
      "the index is : 11728\n",
      "the index is : 11744\n",
      "the index is : 11760\n",
      "the index is : 11776\n",
      "the index is : 11792\n",
      "the index is : 11808\n",
      "the index is : 11824\n",
      "the index is : 11840\n",
      "the index is : 11856\n",
      "the index is : 11872\n",
      "the index is : 11888\n",
      "the index is : 11904\n",
      "the index is : 11920\n",
      "the index is : 11936\n",
      "the index is : 11952\n",
      "the index is : 11968\n",
      "the index is : 11984\n",
      "the index is : 12000\n",
      "Minibatch loss at step 750: 0.723631\n",
      "Minibatch accuracy: 81.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 83.5%\n",
      "the index is : 12016\n",
      "the index is : 12032\n",
      "the index is : 12048\n",
      "the index is : 12064\n",
      "the index is : 12080\n",
      "the index is : 12096\n",
      "the index is : 12112\n",
      "the index is : 12128\n",
      "the index is : 12144\n",
      "the index is : 12160\n",
      "the index is : 12176\n",
      "the index is : 12192\n",
      "the index is : 12208\n",
      "the index is : 12224\n",
      "the index is : 12240\n",
      "the index is : 12256\n",
      "the index is : 12272\n",
      "the index is : 12288\n",
      "the index is : 12304\n",
      "the index is : 12320\n",
      "the index is : 12336\n",
      "the index is : 12352\n",
      "the index is : 12368\n",
      "the index is : 12384\n",
      "the index is : 12400\n",
      "the index is : 12416\n",
      "the index is : 12432\n",
      "the index is : 12448\n",
      "the index is : 12464\n",
      "the index is : 12480\n",
      "the index is : 12496\n",
      "the index is : 12512\n",
      "the index is : 12528\n",
      "the index is : 12544\n",
      "the index is : 12560\n",
      "the index is : 12576\n",
      "the index is : 12592\n",
      "the index is : 12608\n",
      "the index is : 12624\n",
      "the index is : 12640\n",
      "the index is : 12656\n",
      "the index is : 12672\n",
      "the index is : 12688\n",
      "the index is : 12704\n",
      "the index is : 12720\n",
      "the index is : 12736\n",
      "the index is : 12752\n",
      "the index is : 12768\n",
      "the index is : 12784\n",
      "the index is : 12800\n",
      "Minibatch loss at step 800: 0.957963\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 83.4%\n",
      "the index is : 12816\n",
      "the index is : 12832\n",
      "the index is : 12848\n",
      "the index is : 12864\n",
      "the index is : 12880\n",
      "the index is : 12896\n",
      "the index is : 12912\n",
      "the index is : 12928\n",
      "the index is : 12944\n",
      "the index is : 12960\n",
      "the index is : 12976\n",
      "the index is : 12992\n",
      "the index is : 13008\n",
      "the index is : 13024\n",
      "the index is : 13040\n",
      "the index is : 13056\n",
      "the index is : 13072\n",
      "the index is : 13088\n",
      "the index is : 13104\n",
      "the index is : 13120\n",
      "the index is : 13136\n",
      "the index is : 13152\n",
      "the index is : 13168\n",
      "the index is : 13184\n",
      "the index is : 13200\n",
      "the index is : 13216\n",
      "the index is : 13232\n",
      "the index is : 13248\n",
      "the index is : 13264\n",
      "the index is : 13280\n",
      "the index is : 13296\n",
      "the index is : 13312\n",
      "the index is : 13328\n",
      "the index is : 13344\n",
      "the index is : 13360\n",
      "the index is : 13376\n",
      "the index is : 13392\n",
      "the index is : 13408\n",
      "the index is : 13424\n",
      "the index is : 13440\n",
      "the index is : 13456\n",
      "the index is : 13472\n",
      "the index is : 13488\n",
      "the index is : 13504\n",
      "the index is : 13520\n",
      "the index is : 13536\n",
      "the index is : 13552\n",
      "the index is : 13568\n",
      "the index is : 13584\n",
      "the index is : 13600\n",
      "Minibatch loss at step 850: 0.908044\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.3%\n",
      "the index is : 13616\n",
      "the index is : 13632\n",
      "the index is : 13648\n",
      "the index is : 13664\n",
      "the index is : 13680\n",
      "the index is : 13696\n",
      "the index is : 13712\n",
      "the index is : 13728\n",
      "the index is : 13744\n",
      "the index is : 13760\n",
      "the index is : 13776\n",
      "the index is : 13792\n",
      "the index is : 13808\n",
      "the index is : 13824\n",
      "the index is : 13840\n",
      "the index is : 13856\n",
      "the index is : 13872\n",
      "the index is : 13888\n",
      "the index is : 13904\n",
      "the index is : 13920\n",
      "the index is : 13936\n",
      "the index is : 13952\n",
      "the index is : 13968\n",
      "the index is : 13984\n",
      "the index is : 14000\n",
      "the index is : 14016\n",
      "the index is : 14032\n",
      "the index is : 14048\n",
      "the index is : 14064\n",
      "the index is : 14080\n",
      "the index is : 14096\n",
      "the index is : 14112\n",
      "the index is : 14128\n",
      "the index is : 14144\n",
      "the index is : 14160\n",
      "the index is : 14176\n",
      "the index is : 14192\n",
      "the index is : 14208\n",
      "the index is : 14224\n",
      "the index is : 14240\n",
      "the index is : 14256\n",
      "the index is : 14272\n",
      "the index is : 14288\n",
      "the index is : 14304\n",
      "the index is : 14320\n",
      "the index is : 14336\n",
      "the index is : 14352\n",
      "the index is : 14368\n",
      "the index is : 14384\n",
      "the index is : 14400\n",
      "Minibatch loss at step 900: 0.633094\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.4%\n",
      "the index is : 14416\n",
      "the index is : 14432\n",
      "the index is : 14448\n",
      "the index is : 14464\n",
      "the index is : 14480\n",
      "the index is : 14496\n",
      "the index is : 14512\n",
      "the index is : 14528\n",
      "the index is : 14544\n",
      "the index is : 14560\n",
      "the index is : 14576\n",
      "the index is : 14592\n",
      "the index is : 14608\n",
      "the index is : 14624\n",
      "the index is : 14640\n",
      "the index is : 14656\n",
      "the index is : 14672\n",
      "the index is : 14688\n",
      "the index is : 14704\n",
      "the index is : 14720\n",
      "the index is : 14736\n",
      "the index is : 14752\n",
      "the index is : 14768\n",
      "the index is : 14784\n",
      "the index is : 14800\n",
      "the index is : 14816\n",
      "the index is : 14832\n",
      "the index is : 14848\n",
      "the index is : 14864\n",
      "the index is : 14880\n",
      "the index is : 14896\n",
      "the index is : 14912\n",
      "the index is : 14928\n",
      "the index is : 14944\n",
      "the index is : 14960\n",
      "the index is : 14976\n",
      "the index is : 14992\n",
      "the index is : 15008\n",
      "the index is : 15024\n",
      "the index is : 15040\n",
      "the index is : 15056\n",
      "the index is : 15072\n",
      "the index is : 15088\n",
      "the index is : 15104\n",
      "the index is : 15120\n",
      "the index is : 15136\n",
      "the index is : 15152\n",
      "the index is : 15168\n",
      "the index is : 15184\n",
      "the index is : 15200\n",
      "Minibatch loss at step 950: 0.962489\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 83.7%\n",
      "the index is : 15216\n",
      "the index is : 15232\n",
      "the index is : 15248\n",
      "the index is : 15264\n",
      "the index is : 15280\n",
      "the index is : 15296\n",
      "the index is : 15312\n",
      "the index is : 15328\n",
      "the index is : 15344\n",
      "the index is : 15360\n",
      "the index is : 15376\n",
      "the index is : 15392\n",
      "the index is : 15408\n",
      "the index is : 15424\n",
      "the index is : 15440\n",
      "the index is : 15456\n",
      "the index is : 15472\n",
      "the index is : 15488\n",
      "the index is : 15504\n",
      "the index is : 15520\n",
      "the index is : 15536\n",
      "the index is : 15552\n",
      "the index is : 15568\n",
      "the index is : 15584\n",
      "the index is : 15600\n",
      "the index is : 15616\n",
      "the index is : 15632\n",
      "the index is : 15648\n",
      "the index is : 15664\n",
      "the index is : 15680\n",
      "the index is : 15696\n",
      "the index is : 15712\n",
      "the index is : 15728\n",
      "the index is : 15744\n",
      "the index is : 15760\n",
      "the index is : 15776\n",
      "the index is : 15792\n",
      "the index is : 15808\n",
      "the index is : 15824\n",
      "the index is : 15840\n",
      "the index is : 15856\n",
      "the index is : 15872\n",
      "the index is : 15888\n",
      "the index is : 15904\n",
      "the index is : 15920\n",
      "the index is : 15936\n",
      "the index is : 15952\n",
      "the index is : 15968\n",
      "the index is : 15984\n",
      "the index is : 16000\n",
      "Minibatch loss at step 1000: 0.972882\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.8%\n",
      "Test accuracy: 89.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    print(\"the index is :\",offset)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** [16, 14, 14, 1]\n",
      "#### [16, 7, 7, 1]\n",
      "***** [10000, 14, 14, 1]\n",
      "#### [10000, 7, 7, 1]\n",
      "***** [10000, 14, 14, 1]\n",
      "#### [10000, 7, 7, 1]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  \n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 *  num_channels, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    pool = tf.nn.max_pool(data, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    hidden = tf.nn.relu(pool)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(\"*****\",shape)  # 14*14*16\n",
    "    pool = tf.nn.max_pool(pool, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    hidden = tf.nn.relu(pool)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(\"####\",shape)  # 7*7*16\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.582308\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 8.4%\n",
      "Minibatch loss at step 50: 2.212067\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.3%\n",
      "Minibatch loss at step 100: 2.100518\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 26.4%\n",
      "Minibatch loss at step 150: 2.012785\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 37.6%\n",
      "Minibatch loss at step 200: 1.969894\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 45.9%\n",
      "Minibatch loss at step 250: 1.435222\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 43.0%\n",
      "Minibatch loss at step 300: 1.432277\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 60.0%\n",
      "Minibatch loss at step 350: 1.340147\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 66.9%\n",
      "Minibatch loss at step 400: 1.161930\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 67.2%\n",
      "Minibatch loss at step 450: 1.293348\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 69.5%\n",
      "Minibatch loss at step 500: 1.222820\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 550: 0.877531\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 600: 1.010693\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 650: 0.640181\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 72.8%\n",
      "Minibatch loss at step 700: 1.050980\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 74.7%\n",
      "Minibatch loss at step 750: 1.127785\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 74.1%\n",
      "Minibatch loss at step 800: 1.194775\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 850: 0.778648\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 900: 0.728274\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 950: 1.283348\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1000: 1.418202\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.6%\n",
      "Test accuracy: 82.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #print(\"the index is :\",offset)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "明显感觉训练速度加快，因为没有引入其他参数,但是准确率会下降，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** [16, 14, 14, 1]\n",
      "#### [16, 7, 7, 1]\n",
      "***** [10000, 14, 14, 1]\n",
      "#### [10000, 7, 7, 1]\n",
      "***** [10000, 14, 14, 1]\n",
      "#### [10000, 7, 7, 1]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "dropout_rate = 0.3  # == 1 - keep_prob\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  \n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 *  num_channels, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    pool = tf.nn.max_pool(data, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    hidden1 = tf.nn.relu(pool)\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training) # training 时才drop_out\n",
    "    shape = hidden1_drop.get_shape().as_list()\n",
    "    print(\"*****\",shape)  # 14*14*16\n",
    "    pool = tf.nn.max_pool(pool, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    hidden2 = tf.nn.relu(pool)\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training) # training 时才drop_out\n",
    "    shape = hidden2_drop.get_shape().as_list()\n",
    "    print(\"####\",shape)  # 7*7*16\n",
    "    reshape = tf.reshape( hidden2_drop, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden3 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden3, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.877772\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 11.2%\n",
      "Minibatch loss at step 50: 2.154980\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 11.2%\n",
      "Minibatch loss at step 100: 2.069037\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 30.5%\n",
      "Minibatch loss at step 150: 1.915334\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 48.5%\n",
      "Minibatch loss at step 200: 1.880721\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 44.9%\n",
      "Minibatch loss at step 250: 1.484746\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 45.1%\n",
      "Minibatch loss at step 300: 1.547102\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 57.5%\n",
      "Minibatch loss at step 350: 1.408836\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 67.2%\n",
      "Minibatch loss at step 400: 1.443589\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 66.2%\n",
      "Minibatch loss at step 450: 1.344938\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 67.5%\n",
      "Minibatch loss at step 500: 1.470896\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 70.3%\n",
      "Minibatch loss at step 550: 1.202961\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 71.2%\n",
      "Minibatch loss at step 600: 1.325815\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 650: 0.934148\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 72.1%\n",
      "Minibatch loss at step 700: 1.356006\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 750: 1.341113\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 72.1%\n",
      "Minibatch loss at step 800: 1.507911\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 73.0%\n",
      "Minibatch loss at step 850: 0.836818\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 900: 0.909063\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 71.7%\n",
      "Minibatch loss at step 950: 1.599341\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 72.2%\n",
      "Test accuracy: 75.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #print(\"the index is :\",offset)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,training: True}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不知道为啥效果差了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       # not shown in the book\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** [16, 14, 14, 1]\n",
      "#### [16, 7, 7, 1]\n",
      "***** [10000, 14, 14, 1]\n",
      "#### [10000, 7, 7, 1]\n",
      "***** [10000, 14, 14, 1]\n",
      "#### [10000, 7, 7, 1]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  \n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 *  num_channels, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    pool = tf.nn.max_pool(data, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    hidden = tf.nn.relu(pool)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(\"*****\",shape)  # 14*14*16\n",
    "    pool = tf.nn.max_pool(pool, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    hidden = tf.nn.relu(pool)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    print(\"####\",shape)  # 7*7*16\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "  # Optimizer.\n",
    "        \n",
    "  initial_learning_rate = 0.1\n",
    "  decay_steps = 100\n",
    "  decay_rate = 1/10\n",
    "  global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "  learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                           decay_steps, decay_rate)\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "#training_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.422063\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 13.6%\n",
      "Minibatch loss at step 50: 2.100040\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 20.8%\n",
      "Minibatch loss at step 100: 1.747661\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 39.4%\n",
      "Minibatch loss at step 150: 1.622249\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 54.3%\n",
      "Minibatch loss at step 200: 1.499662\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 61.3%\n",
      "Minibatch loss at step 250: 0.800409\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 64.7%\n",
      "Minibatch loss at step 300: 1.196800\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 350: 0.916491\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 72.7%\n",
      "Minibatch loss at step 400: 0.773869\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 74.5%\n",
      "Minibatch loss at step 450: 0.960377\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 73.4%\n",
      "Minibatch loss at step 500: 1.182822\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 550: 0.629669\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 600: 0.647169\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 650: 0.416481\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 700: 0.963227\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 750: 1.087667\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 800: 1.138857\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 850: 0.820524\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 900: 0.731906\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 950: 1.230455\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1000: 1.480711\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1050: 0.547496\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1100: 1.534067\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 74.9%\n",
      "Minibatch loss at step 1150: 0.479234\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1200: 1.334608\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 1250: 0.490637\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1300: 0.854861\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 1350: 0.735215\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 1400: 0.793895\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 1450: 0.725196\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1500: 0.724184\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 1550: 0.982124\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 1600: 1.087475\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1650: 0.960816\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 75.7%\n",
      "Minibatch loss at step 1700: 0.717977\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1750: 0.700631\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 1800: 0.531576\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1850: 1.402037\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1900: 0.377280\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 1950: 0.309900\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 2000: 0.804992\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 2050: 0.915897\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2100: 0.525997\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 2150: 0.510718\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 2200: 0.731805\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 2250: 1.060309\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2300: 0.565403\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2350: 0.716390\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 2400: 0.955503\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 2450: 0.589511\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2500: 0.595610\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 2550: 0.487301\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2600: 0.606007\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 2650: 0.578156\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2700: 0.260961\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 2750: 0.669490\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 2800: 0.538171\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 2850: 0.518591\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 2900: 0.718939\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 2950: 0.704178\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3000: 0.466688\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 3050: 0.983705\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3100: 1.270160\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 3150: 1.262619\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3200: 1.261049\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 3250: 1.201562\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3300: 0.900052\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 3350: 0.340099\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3400: 0.973073\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3450: 0.854332\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 3500: 1.267250\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 3550: 1.119334\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3600: 0.877688\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 3650: 0.872260\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 3700: 0.383587\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 3750: 0.861185\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3800: 0.886083\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 3850: 0.609971\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 3900: 0.220230\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 3950: 0.403663\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 4000: 0.327124\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 4050: 0.842987\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 4100: 0.456471\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 4150: 0.881270\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 4200: 0.986857\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 4250: 0.398746\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 4300: 0.753610\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 4350: 0.607189\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 4400: 0.626054\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 4450: 0.803142\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 4500: 0.624875\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 4550: 1.021535\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 4600: 0.828757\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 4650: 1.213529\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 4700: 0.976800\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 4750: 1.075863\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 4800: 0.342540\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 4850: 0.528014\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 4900: 1.352603\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 4950: 0.467309\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 5000: 0.959071\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 5050: 0.846731\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 5100: 0.806805\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 5150: 0.867931\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 5200: 1.383674\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 5250: 0.497712\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 5300: 0.899555\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 5350: 0.395583\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 5400: 0.760370\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 5450: 1.305845\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 5500: 0.925673\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 5550: 1.929034\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 5600: 1.024947\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 5650: 1.426724\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 5700: 0.566314\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 5750: 0.973928\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 5800: 0.662123\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 5850: 0.916700\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 5900: 0.334196\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 5950: 1.101129\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 6000: 0.661039\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 6050: 0.177255\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 6100: 0.827447\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 6150: 0.890110\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 6200: 0.706741\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 6250: 0.819759\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 6300: 0.487432\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 6350: 1.233547\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 6400: 0.690764\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 6450: 0.637757\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 6500: 0.303922\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 6550: 0.554710\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 6600: 0.890260\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 6650: 0.891963\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 6700: 0.499270\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 6750: 0.596932\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 6800: 0.576319\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 6850: 1.259178\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 6900: 0.236839\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 6950: 1.415339\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 7000: 0.888637\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 7050: 0.562558\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 7100: 0.455757\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 7150: 1.087668\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 7200: 0.104187\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 7250: 0.493594\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 7300: 0.160880\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 7350: 0.636189\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 7400: 0.416663\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 7450: 0.622425\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 7500: 0.837908\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 7550: 0.884058\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 7600: 1.052418\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 7650: 0.873571\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 7700: 0.796967\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 7750: 0.407543\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 7800: 0.343307\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 7850: 0.829924\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 7900: 0.873336\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 7950: 0.729375\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 8000: 0.482852\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 8050: 0.586577\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 8100: 0.341294\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 8150: 1.053243\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 8200: 1.344825\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 8250: 1.250017\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 8300: 0.510679\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 8350: 1.089775\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 8400: 0.621777\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 8450: 0.538638\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 8500: 0.725475\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 8550: 1.288696\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 8600: 0.775391\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 8650: 0.729280\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 8700: 0.334778\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 8750: 0.595762\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 8800: 0.409094\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 8850: 0.481043\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 8900: 0.686860\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 8950: 0.694711\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 9000: 0.370752\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 9050: 0.708274\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 9100: 0.634090\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 9150: 0.633802\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 9200: 0.313078\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 9250: 0.277574\n",
      "Minibatch accuracy: 93.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 9300: 0.196981\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 9350: 1.272643\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 9400: 0.496037\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 9450: 0.647559\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 9500: 0.642931\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 9550: 1.101918\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 9600: 0.525783\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 9650: 1.010693\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 9700: 0.767415\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 9750: 0.834522\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 9800: 0.705222\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 9850: 0.986966\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 9900: 0.437375\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 9950: 0.578152\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.8%\n",
      "Test accuracy: 85.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #print(\"the index is :\",offset)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 50 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels)) \n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
